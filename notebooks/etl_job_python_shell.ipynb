{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "s3_bucket = \"amazon-forecast-blood-analysis\"\n",
    "athena_table = \"blood_blood_analysis\"\n",
    "athena_database = \"blood_analisys\"\n",
    "\n",
    "# Realizar Query no Athena com o wr e buscar os dados dos d - 30 enviados pelo IoT Core\n",
    "# Realizar resample dos dados que sao coletados de 5 min em 5 min para hora em hora\n",
    "# Subir esses dados para o s3 criando o catalog com o WR\n",
    "\n",
    "# TODO: alterar query para D - 30\n",
    "# df_read_athena = wr.athena.read_sql_query(f\"SELECT * FROM {athena_table}\", database=athena_database)\n",
    "blood_five_minutes = df_read_athena.sort_values(by='timestamp',ascending=True)\n",
    "blood_five_minutes = blood_five_minutes.dropna()\n",
    "\n",
    "unique_ids = blood_five_minutes['user_id'].unique() # Get Unique ids to iterate\n",
    "appended_data = []\n",
    "\n",
    "for ids in unique_ids:\n",
    "    spplitted_data = blood_five_minutes.loc[blood_five_minutes['user_id'] == str(ids)]\n",
    "\n",
    "    # Fazer resample convertendo de 5 em 5 min para dados de 1 em 1 hora.\n",
    "    data_series = spplitted_data.set_index('timestamp')\n",
    "    data_series.index = pd.to_datetime(data_series.index)\n",
    "    data_series = data_series.resample('1H').bfill()\n",
    "    \n",
    "    blood_analysis_hourly = data_series.reset_index()\n",
    "    blood_analysis_hourly['timestamp'] = blood_analysis_hourly['timestamp'].dt.strftime('%Y-%m-%d %H:%m:%S')\n",
    "    blood_analysis_hourly = blood_analysis_hourly.drop(['partition_0'], axis=1)\n",
    "    blood_analysis_hourly = blood_analysis_hourly.drop(['insulina'], axis=1) # Removendo insulina\n",
    "    blood_analysis_hourly = blood_analysis_hourly.drop(['carbo'], axis=1) # Removendo carboidrato\n",
    "    \n",
    "    appended_data.append(blood_analysis_hourly)\n",
    "\n",
    "concatenated_df = pd.concat(appended_data, ignore_index=True)\n",
    "\n",
    "s3_path_glucose = f\"s3://{s3_bucket}/stage/blood_analysis/glucose/{today}/\"\n",
    "s3_path_df = {s3_path_glucose : {'df_name' : concatenated_df, 'table_name' : 'blood_analysis_stage_hourly'}}\n",
    "\n",
    "for s3_path, values in s3_path_df.items():\n",
    "    wr.s3.to_csv(\n",
    "        df=values['df_name'],\n",
    "        path=s3_path,\n",
    "        index=False,\n",
    "        dataset=True,\n",
    "        mode=\"overwrite\",\n",
    "        database=\"blood_analisys\",\n",
    "        table=values['table_name']\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}